{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11358350,"sourceType":"datasetVersion","datasetId":7108637},{"sourceId":11405956,"sourceType":"datasetVersion","datasetId":7144570},{"sourceId":11435724,"sourceType":"datasetVersion","datasetId":7162925},{"sourceId":11480260,"sourceType":"datasetVersion","datasetId":7195360}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 0.1. Install Dependencies","metadata":{}},{"cell_type":"code","source":"# Install required packages\nget_ipython().run_line_magic('pip', 'uninstall -qy google-genai')\nget_ipython().run_line_magic('pip', 'install -qU \"google-genai==1.7.0\" \"pandas\" \"pytrends\"')\n\nprint(\"✅ Packages installed.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 0.2. Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport warnings\n\nimport pandas as pd\nfrom google import genai\nfrom google.genai import types as genai_types\nfrom kaggle_secrets import UserSecretsClient\nfrom IPython.display import Markdown, display\nfrom pytrends.request import TrendReq\n\n# Initialize PyTrends\ntry:\n    pytrends_client = TrendReq(hl='en-US', tz=360)\n    print(\"✅ PyTrends initialized.\")\nexcept Exception as e:\n    print(f\"⚠️ PyTrends init failed: {e}\")\n    pytrends_client = None\n\nwarnings.filterwarnings(\"ignore\")\nprint(\"✅ Libraries ready.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 0.3. API Client Initialization (using Kaggle Secrets)","metadata":{}},{"cell_type":"code","source":"client = None\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    client = genai.Client(api_key=GOOGLE_API_KEY)\n    print(\"✅ GenAI client initialized.\")\nexcept NameError:\n    print(\"❌ UserSecretsClient not found. Are you running outside Kaggle?\")\nexcept Exception as e:\n    print(f\"❌ Failed to init GenAI client: {e}\")\n\nif client is None:\n    print(\"⚠️ GenAI client is unavailable. API calls will fail.\")\n    # raise RuntimeError(\"GenAI client init failed.\")  # Uncomment if critical","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 0.4. Global Configuration","metadata":{}},{"cell_type":"code","source":"# Model and style configuration\nMODEL_NAME = \"gemini-2.0-flash\"  # Recommended: \"gemini-2.0-flash\", \"gemini-1.5-pro-latest\"\nGENERATION_STYLE = \"insightful\"  # E.g., \"engaging\", \"technical\", \"professional\", etc.\n\nprint(f\"✅ Model: {MODEL_NAME}\")\nprint(f\"🧠 Style: {GENERATION_STYLE}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 0.5. Define Output Data Structure (VideoMetadata TypedDict)","metadata":{}},{"cell_type":"code","source":"from typing_extensions import TypedDict  # Use `typing` if Python >= 3.8\n\nclass VideoMetadata(TypedDict):\n    topic_name: str\n    title: str\n    thumbnail_prompt: str\n    description: str\n    hashtags: list[str]\n    tags: list[str]\n    chapters: str\n\nDEFAULT_METADATA: VideoMetadata = {\n    \"topic_name\": \"\",\n    \"title\": \"\",\n    \"thumbnail_prompt\": \"\",\n    \"description\": \"\",\n    \"hashtags\": [],\n    \"tags\": [],\n    \"chapters\": \"\"\n}\n\nprint(\"✅ VideoMetadata structure and defaults defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ==========================================\n# 1. PROJECT OVERVIEW & USE CASE\n# ==========================================","metadata":{}},{"cell_type":"markdown","source":"# 🧠 1. Introduction & Project Overview\n\n## 🎯 Objective\nIn this project, we develop a **GenAI-powered agent** for YouTube creators. It generates complete metadata (title, topic, description, tags, chapters, thumbnail prompt) based on:\n- A set of input ideas (**Scenario 1** – for upcoming livestream),\n- or a full transcript (**Scenario 2** – for uploaded videos).\n\n## 🤖 Key Features\nThis agent leverages **Gemini** models to:\n- Generate structured, high-quality YouTube metadata;\n- Ground responses using the built-in **Google Search tool**;\n- Handle long transcripts via **Gemini's long context window**;\n- Generate text prompts suitable for AI image generators.\n\n## ✅ GenAI Capabilities Demonstrated\nThis notebook demonstrates **at least 5** distinct GenAI features relevant to the Capstone project:\n- ✅ Structured Output / JSON Mode / Controlled Generation\n- ✅ Grounding (via Google Search Tool)\n- ✅ Retrieval Augmented Generation (RAG) concepts (using search results to inform generation)\n- ✅ Long Context Window (handling full transcripts)\n- ✅ Few-shot Prompting (using examples in prompts)\n\n## 📊 Project Scenarios\n\n| Scenario | Input | Output | Use Case |\n|----------|--------|--------|----------|\n| 1️⃣ Pre-Stream | Topic + Theses | Title, Description, Tags, Thumbnail Prompt | Planning metadata for an upcoming livestream |\n| 2️⃣ Post-Video | Full Transcript | Title, Description, Tags, Chapters, Thumbnail Prompt | Generating/enhancing metadata for an existing video |","metadata":{}},{"cell_type":"markdown","source":"# ==========================================\n# 2. UTILITY FUNCTIONS & HELPERS\n# ==========================================\n\n### 2.1. Google Trends Fetcher (Optional Enhancement for Tags)","metadata":{}},{"cell_type":"code","source":"def get_google_trends_for_query(query: str, region: str = \"US\", timeframe: str = \"now 7-d\") -> list[str]:\n    \"\"\"\n    Fetches top related search queries from Google Trends using pytrends.\n\n    Args:\n        query (str): The search term to analyze.\n        region (str): Geographical region code (default is 'US').\n        timeframe (str): Time window for the trend data (default is 'now 7-d').\n\n    Returns:\n        list[str]: A list of up to 5 related trending queries. Returns an empty list if unavailable.\n    \"\"\"\n    if 'pytrends_client' not in globals() or pytrends_client is None:\n        return []\n\n    try:\n        pytrends_client.build_payload(kw_list=[query], geo=region, timeframe=timeframe)\n        related_queries = pytrends_client.related_queries()\n        top_df = related_queries.get(query, {}).get(\"top\")\n\n        if isinstance(top_df, pd.DataFrame) and not top_df.empty:\n            return top_df[\"query\"].head(5).tolist()\n\n        return []\n    except Exception:\n        return []\n\nprint(\"✅ Google Trends utility function ready.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.2. Metadata Rendering Function","metadata":{}},{"cell_type":"code","source":"def render_metadata_md(metadata: VideoMetadata):\n    \"\"\"Render the video metadata dictionary as a formatted Markdown block.\"\"\"\n    if not isinstance(metadata, dict):\n        return\n\n    title = metadata.get(\"title\", \"N/A\")\n    topic = metadata.get(\"topic_name\", \"N/A\")\n    description = metadata.get(\"description\", \"N/A\")\n    chapters_raw = metadata.get(\"chapters\", \"\")\n    hashtags_list = metadata.get(\"hashtags\", [])\n    tags_list = metadata.get(\"tags\", [])\n    thumbnail_prompt = metadata.get(\"thumbnail_prompt\", \"N/A\")\n\n    hashtags_md = \" \".join(\n        list(dict.fromkeys(f\"#{tag.strip().lstrip('#').split()[0].lower()}\" for tag in hashtags_list if isinstance(tag, str) and tag.strip()))\n    ) if hashtags_list else \"None\"\n\n    tags_md = \", \".join(\n        list(dict.fromkeys(str(t).strip() for t in tags_list if isinstance(t, str) and str(t).strip()))\n    ) if tags_list else \"None\"\n\n    chapters_md = \"None\"\n    if chapters_raw and isinstance(chapters_raw, str):\n        chapter_lines = [line.strip() for line in chapters_raw.strip().splitlines() if line.strip().startswith(\"➤\")]\n        if chapter_lines:\n            chapters_md = \"\\n\" + \"  \\n\".join(chapter_lines)\n\n    md_output = f\"\"\"\n🎥 **Title:**\n{title}\n\n📌 **Topic:**\n{topic}\n\n📝 **Description:**\n{description}\n\n🎬 **Chapters:**\n{chapters_md}\n\n🏷️ **Hashtags:**\n{hashtags_md}\n\n🔍 **SEO Tags:**\n{tags_md}\n\n🖼️ **Thumbnail Prompt:**  \n{thumbnail_prompt}\n\"\"\"\n\n    try:\n        display(Markdown(md_output))\n    except Exception:\n        pass\n\nprint(\"✅ Metadata renderer ready.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ==========================================\n# 3. CORE METADATA GENERATION COMPONENTS\n# ==========================================\n# This section contains the core building blocks:\n# - Prompt templates defining instructions for the LLM.\n# - Python functions that call the LLM with these prompts to generate specific metadata parts.","metadata":{}},{"cell_type":"markdown","source":"### 3.1. Topic & Title Generation","metadata":{}},{"cell_type":"markdown","source":"#### 3.1.A. Prompt Template (for Text Inputs)","metadata":{}},{"cell_type":"code","source":"TOPIC_TITLE_PROMPT_FROM_INPUTS = \"\"\"\nYou are a YouTube metadata assistant. Your task is to generate a clear topic and a catchy title for a YouTube video based on the provided user input (initial topic/idea) and keywords/theses.\n\nGenerate TWO lines:\n1. A short and descriptive topic summarizing what the video is about.\n   - Max 100 characters.\n2. A concise and engaging YouTube-style title (preferably under 70 characters).\n\nFormat:\n<Generated Topic>\n<Generated Title>\n\nNO explanations, no labels, no extra text.\n\n---\nUser Input:\n{topic}\n\nTheses / Keywords:\n{theses}\n---\n\"\"\"\n\nprint(\"✅ Topic & Title prompt (from user input) ready.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 3.1.B. Function (for Text Inputs)","metadata":{}},{"cell_type":"code","source":"def generate_topic_title_from_inputs(topic: str, theses: str) -> tuple[str, str]:\n    \"\"\"\n    Generates a topic and a catchy title using Gemini based on user-provided topic and theses.\n\n    Args:\n        topic: The user's initial idea.\n        theses: Supporting points or keywords.\n\n    Returns:\n        (topic_name, title) — both strings. Returns (\"\", \"\") on failure.\n    \"\"\"\n    if 'client' not in globals() or client is None:\n        print(\"❌ GenAI client not initialized.\")\n        return \"\", \"\"\n    if 'MODEL_NAME' not in globals():\n        print(\"❌ MODEL_NAME is not defined.\")\n        return \"\", \"\"\n    if not topic or not theses:\n        print(\"⚠️ Missing topic or theses input.\")\n        return \"\", \"\"\n\n    try:\n        prompt = TOPIC_TITLE_PROMPT_FROM_INPUTS.format(topic=topic, theses=theses)\n\n        response = client.models.generate_content(\n            model=MODEL_NAME,\n            contents=[prompt]\n        )\n\n        text = response.text.strip()\n        lines = text.split(\"\\n\", 1)\n\n        if len(lines) == 2:\n            topic_name = lines[0].strip().removeprefix(\"- Line 1:\").strip()\n            title = lines[1].strip().removeprefix(\"- Line 2:\").strip()\n            return topic_name, title\n        else:\n            print(\"⚠️ Unexpected output format.\")\n            return \"\", text if len(text) < 100 else \"\"\n\n    except Exception as e:\n        print(f\"❌ Generation error: {e}\")\n        return \"\", \"\"\n\nprint(\"✅ Topic/title generation function ready.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 3.1.C. Prompt Template (for Transcript Analysis)","metadata":{}},{"cell_type":"code","source":"TOPIC_TITLE_PROMPT_FROM_TRANSCRIPT = \"\"\"\nYou are a YouTube metadata assistant. Analyze the **full transcript** of a video to understand its core theme.\n\nGenerate exactly TWO lines:\n1. A concise **topic** summarizing the video's core subject.\n   - Max 100 characters.\n   - A short sentence or phrase.\n2. A **catchy YouTube-style title** (under 70 characters preferred).\n   - Designed to attract viewers interested in the topic.\n\n📌 Format (strict):\n<topic>\n<title>\n\n❌ Do NOT include any labels, numbers, colons, or explanations.\n\n✅ Example:\nUnderstanding Large Language Models in Plain English\nLLMs Explained: How ChatGPT Really Works\n\n---\nFull Transcript:\n{transcript_text}\n---\n\nGenerate the output now:\n\"\"\"\n\nprint(\"✅ Prompt template `TOPIC_TITLE_PROMPT_FROM_TRANSCRIPT` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 3.1.D. Function (for Transcript Analysis)","metadata":{}},{"cell_type":"code","source":"def generate_topic_title_from_transcript(transcript_text: str) -> tuple[str, str]:\n    \"\"\"\n    Generates a topic and title by analyzing a full video transcript using the Gemini model.\n\n    Args:\n        transcript_text (str): The complete video transcript.\n\n    Returns:\n        tuple[str, str]: A pair of strings (topic, title), or (\"\", \"\") on failure.\n    \"\"\"\n    if 'client' not in globals() or client is None:\n        print(\"❌ GenAI client is not initialized.\")\n        return \"\", \"\"\n\n    if 'MODEL_NAME' not in globals():\n        print(\"❌ MODEL_NAME is not defined.\")\n        return \"\", \"\"\n\n    if not transcript_text:\n        print(\"⚠️ Empty transcript. Skipping topic/title generation.\")\n        return \"\", \"\"\n\n    try:\n        prompt = TOPIC_TITLE_PROMPT_FROM_TRANSCRIPT.format(transcript_text=transcript_text)\n        response = client.models.generate_content(model=MODEL_NAME, contents=[prompt])\n        text = response.text.strip()\n        lines = text.split(\"\\n\", 1)\n\n        if len(lines) == 2:\n            topic = lines[0].strip()\n            title = lines[1].strip()\n\n            # Handle accidental labeling\n            if topic.lower().startswith(\"- line 1:\"):\n                topic = topic.split(\":\", 1)[-1].strip()\n            if title.lower().startswith(\"- line 2:\"):\n                title = title.split(\":\", 1)[-1].strip()\n\n            return topic, title\n        else:\n            return \"\", text if len(text) < 100 else \"\"\n\n    except Exception as e:\n        print(f\"❌ Error during topic/title generation from transcript: {e}\")\n        return \"\", \"\"\n\nprint(\"✅ Function `generate_topic_title_from_transcript` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.2. Description Generation (with Grounding)","metadata":{}},{"cell_type":"markdown","source":"#### 3.2.A. Prompt Template","metadata":{}},{"cell_type":"code","source":"# Prompt template for generating a YouTube video description using topic, title,\n# content (theses or transcript), and grounded Google Search results.\n\nDESCRIPTION_PROMPT_TEMPLATE = \"\"\"\nYou are a creative YouTube content writer. Your task is to write a short, compelling video description based on the video topic, title, main talking points (or transcript), and relevant Google Search results for context. Use a '{style}' tone.\n\nGuidelines:\n- Begin with a short, {style} introduction.\n- If given theses, summarize them using a concise bulleted list.\n- If given a transcript, summarize the key ideas in flowing text (no bullets).\n- Use search results as context where relevant, but prioritize the main content.\n- Avoid generic or overly promotional language.\n- Write in English.\n- Output only the description text (no headings, labels, or extra explanation).\n\n---\n🎯 Topic: {topic_name}\n🎬 Title: {title}\n📌 Main Points / Transcript Snippet:\n{main_points_or_transcript}\n\n🔍 Background Search Results:\n{search_results}\n---\n\nWrite the final video description below:\n\"\"\"\n\nprint(\"✅ Prompt template `DESCRIPTION_PROMPT_TEMPLATE` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 3.2.B. Function","metadata":{}},{"cell_type":"code","source":"def generate_description_with_search(topic_name: str, title: str, main_points_or_transcript: str) -> str:\n    \"\"\"\n    Generates a YouTube video description using the Gemini model,\n    grounded with Google Search results for context.\n\n    Args:\n        topic_name: The main topic of the video.\n        title: The title of the video.\n        main_points_or_transcript: Either key points (Scenario 1) or full transcript (Scenario 2).\n\n    Returns:\n        A generated video description string, or an empty string on failure.\n    \"\"\"\n    if 'client' not in globals() or client is None:\n        return \"\"\n    if 'MODEL_NAME' not in globals() or 'GENERATION_STYLE' not in globals():\n        return \"\"\n    if not topic_name or not title or not main_points_or_transcript:\n        return \"\"\n\n    # --- Step 1: Google Search Tool (Grounding) ---\n    search_text = \"No background search information available.\"\n    try:\n        from google.genai import types\n        snippet = main_points_or_transcript[:200]\n        search_query = f\"Latest insights about: {topic_name} - {title}. Related points: {snippet}\"\n        config_with_search = types.GenerateContentConfig(\n            tools=[types.Tool(google_search=types.GoogleSearch())]\n        )\n        search_response = client.models.generate_content(\n            model=MODEL_NAME,\n            contents=[search_query],\n            config=config_with_search\n        )\n        search_text = search_response.candidates[0].content.parts[0].text.strip()\n    except Exception:\n        pass  # Proceed without search context if error occurs\n\n    # --- Step 2: Generate Description ---\n    try:\n        prompt = DESCRIPTION_PROMPT_TEMPLATE.format(\n            topic_name=topic_name.strip(),\n            title=title.strip(),\n            main_points_or_transcript=main_points_or_transcript.strip(),\n            search_results=search_text,\n            style=GENERATION_STYLE\n        )\n        response = client.models.generate_content(\n            model=MODEL_NAME,\n            contents=[prompt]\n        )\n        return response.text.strip()\n    except Exception:\n        return \"\"\n\nprint(\"✅ Function `generate_description_with_search` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.3. Tags & Keywords Generation (JSON Output)","metadata":{}},{"cell_type":"markdown","source":"#### 3.3.A. Prompt Template","metadata":{}},{"cell_type":"code","source":"TAGS_PROMPT_TEMPLATE = \"\"\"\nYou are a YouTube SEO expert. Based on the video topic and description below, generate optimized metadata.\n\nGenerate:\n- A list of up to 10 relevant **hashtags**:\n  - Start each with '#'\n  - Lowercase only\n  - Use single words or short phrases (e.g., #generativeai)\n- A list of **SEO keyword tags**:\n  - Lowercase\n  - Single words or 2–4 word phrases\n  - Avoid generic words like \"cool\", \"video\", etc.\n\nRespond with a **valid JSON object** with two keys:\n- \"hashtags\": [list of strings]\n- \"tags\": [list of strings]\n\nDo not include any explanations or text outside the JSON.\n\n---\n🎯 Topic: {topic_name}\n📝 Description:\n{description}\n---\n\nExample JSON output:\n```json\n{{\n  \"hashtags\": [\"#generativeai\", \"#youtubeai\", \"#videotools\"],\n  \"tags\": [\"ai for content creators\", \"youtube metadata generation\", \"seo for youtube\"]\n}}\n\"\"\"\nprint(\"✅ Prompt template `TAGS_PROMPT_TEMPLATE` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 3.3.B. Function","metadata":{}},{"cell_type":"code","source":"def generate_tags_and_keywords(topic_name: str, description: str, use_trends: bool = True) -> tuple[list[str], list[str]]:\n    \"\"\"\n    Generates hashtags and SEO tags for YouTube videos using the Gemini model,\n    optionally enhanced with Google Trends data.\n    \"\"\"\n    if 'client' not in globals() or client is None:\n        return [], []\n    if 'MODEL_NAME' not in globals():\n        return [], []\n    if not topic_name or not description:\n        return [], []\n\n    hashtags, tags = [], []\n\n    try:\n        prompt = TAGS_PROMPT_TEMPLATE.format(\n            topic_name=topic_name.strip(),\n            description=description.strip()\n        )\n\n        response = client.models.generate_content(\n            model=MODEL_NAME,\n            contents=[prompt]\n        )\n\n        raw_text = response.text.strip()\n\n        # Remove potential code fences\n        if raw_text.startswith(\"```json\"):\n            raw_text = raw_text[7:].strip()\n        if raw_text.startswith(\"```\"):\n            raw_text = raw_text[3:].strip()\n        if raw_text.endswith(\"```\"):\n            raw_text = raw_text[:-3].strip()\n\n        try:\n            tags_json = json.loads(raw_text)\n            hashtags = tags_json.get(\"hashtags\", [])\n            tags = tags_json.get(\"tags\", [])\n            if not isinstance(hashtags, list):\n                hashtags = []\n            if not isinstance(tags, list):\n                tags = []\n        except json.JSONDecodeError:\n            return [], []\n\n    except Exception:\n        return [], []\n\n    # --- Optional: Enhance with Google Trends ---\n    if use_trends and 'get_google_trends_for_query' in globals():\n        try:\n            trends = get_google_trends_for_query(topic_name)\n            if isinstance(trends, list):\n                for t in trends:\n                    t_clean = t.lower().strip()\n                    if t_clean and t_clean not in tags:\n                        tags.append(t_clean)\n                    h_tag = f\"#{t_clean.replace(' ', '')}\"\n                    if h_tag != \"#\" and h_tag not in hashtags:\n                        hashtags.append(h_tag)\n        except Exception:\n            pass\n\n    # --- Final cleanup: ensure all hashtags are clean, start with #, no duplicates ---\n    final_hashtags = []\n    for h in hashtags:\n        if isinstance(h, str):\n            clean = h.strip().lstrip('#').replace(' ', '')\n            if clean:\n                h_tag = f\"#{clean}\"\n                if h_tag not in final_hashtags:\n                    final_hashtags.append(h_tag)\n\n    final_tags = []\n    for t in tags:\n        if isinstance(t, str):\n            clean = t.strip()\n            if clean and clean not in final_tags:\n                final_tags.append(clean)\n\n    return final_hashtags, final_tags\nprint(\"✅ Function `generate_tags_and_keywords` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.4. Chapter Generation (from Transcript)\n# Note: This component is used only in Scenario 2 (metadata from transcript).","metadata":{}},{"cell_type":"markdown","source":"#### 3.4.A. Prompt Template","metadata":{}},{"cell_type":"code","source":"CHAPTERS_PROMPT = \"\"\"\nYou are a YouTube assistant. Analyze the full transcript below and identify all major topic shifts or sections.\n\nYour task:\n- Generate a list of clear and concise chapter titles.\n- Each title must be paired with a precise timestamp in the format HH:MM:SS or MM:SS.\n- Chapters must reflect the actual structure and content flow of the video.\n\nStrict formatting rules:\n- Plain text output ONLY. No markdown, HTML, JSON, or code blocks.\n- DO NOT include any intro, explanation, or summary.\n- Each line MUST follow this format:\n  ➤ HH:MM:SS Chapter Title Here\n- Start each chapter on a new line.\n- Begin with the very first chapter (e.g., ➤ 00:00 Introduction).\n- Use the exact symbol \"➤\" (U+27A4) followed by a space.\n- No numbering (1., 2.), no speaker names, no bullet points.\n\n---\nTranscript:\n{transcript}\n---\n\nNow generate the chapter list only, following the format exactly:\n\"\"\"\n\nprint(\"✅ Prompt template `CHAPTERS_PROMPT` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 3.4.B. Function","metadata":{}},{"cell_type":"code","source":"def generate_chapters_from_transcript(transcript_text: str) -> str:\n    \"\"\"\n    Generates YouTube video chapters by analyzing the full transcript using the Gemini model.\n\n    Args:\n        transcript_text: The full transcript text of the video.\n\n    Returns:\n        A string with formatted chapters (one per line, starting with ➤ HH:MM:SS Title),\n        or an empty string if generation fails.\n    \"\"\"\n    if 'client' not in globals() or client is None:\n        print(\"❌ GenAI client not initialized.\")\n        return \"\"\n    if 'MODEL_NAME' not in globals():\n        print(\"❌ MODEL_NAME not defined.\")\n        return \"\"\n    if not transcript_text:\n        print(\"⚠️ Empty transcript provided.\")\n        return \"\"\n\n    print(f\"🎬 Generating chapters (transcript length: {len(transcript_text)} chars)...\")\n\n    try:\n        prompt = CHAPTERS_PROMPT.format(transcript=transcript_text)\n        response = client.models.generate_content(\n            model=MODEL_NAME,\n            contents=prompt\n        )\n\n        chapters_output = response.text.strip()\n        if chapters_output:\n            num_lines = sum(1 for line in chapters_output.splitlines() if line.startswith(\"➤\"))\n            print(f\"✅ Chapters generated: {num_lines} lines.\")\n        else:\n            print(\"⚠️ Chapter generation returned empty output.\")\n\n        return chapters_output\n\n    except Exception as e:\n        print(f\"❌ Error generating chapters: {e}\")\n        return \"\"\n\nprint(\"✅ Function `generate_chapters_from_transcript` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.5. Thumbnail Prompt Generation","metadata":{}},{"cell_type":"markdown","source":"#### 3.5.A. Prompt Template","metadata":{}},{"cell_type":"code","source":"THUMBNAIL_PROMPT_TEMPLATE = \"\"\"\nYou are a creative visual director crafting image prompts for AI generators (e.g., Midjourney, DALL·E, Stable Diffusion).\nBased on the YouTube video's topic, title, and main points, generate a vivid and relevant prompt for a thumbnail image.\n\nVisual style: **{style}**\n\nRequirements:\n- Focus only on visual elements: setting, composition, key subjects, mood, colors, lighting.\n- No text or captions in the prompt (avoid \"Text: ...\").\n- Avoid real-world names; use symbolic/general descriptors.\n- Output only the prompt text — no explanations or labels.\n\n---\n🎯 Topic: {topic_name}\n🎬 Title: {title}\n📌 Summary / Key Points:\n{main_points_or_transcript}\n---\n\nNow generate the thumbnail image prompt:\n\"\"\"\n\nprint(\"✅ Prompt template `THUMBNAIL_PROMPT_TEMPLATE` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 3.5.B. Function","metadata":{}},{"cell_type":"code","source":"def generate_thumbnail_prompt(topic_name: str, title: str, main_points_or_transcript: str) -> str:\n    \"\"\"\n    Generates a visual prompt for an AI image generator to create a YouTube thumbnail.\n\n    Args:\n        topic_name: Video topic.\n        title: Video title.\n        main_points_or_transcript: Key points or transcript summary.\n\n    Returns:\n        Thumbnail prompt string, or empty string if generation fails.\n    \"\"\"\n    if not all([client, MODEL_NAME, GENERATION_STYLE, topic_name, title, main_points_or_transcript]):\n        print(\"❌ Missing required inputs or client not initialized.\")\n        return \"\"\n\n    print(f\"🎨 Generating thumbnail prompt ({GENERATION_STYLE})...\")\n    try:\n        prompt = THUMBNAIL_PROMPT_TEMPLATE.format(\n            topic_name=topic_name.strip(),\n            title=title.strip(),\n            main_points_or_transcript=main_points_or_transcript.strip(),\n            style=GENERATION_STYLE\n        )\n\n        response = client.models.generate_content(\n            model=MODEL_NAME,\n            contents=[prompt]\n        )\n\n        text = response.text.strip()\n        if not text:\n            print(\"⚠️ Empty response.\")\n            return \"\"\n\n        print(\"✅ Thumbnail prompt generated.\")\n        return text\n\n    except Exception as e:\n        print(f\"❌ Error generating thumbnail prompt: {e}\")\n        return \"\"\nprint(\"✅ Function `generate_thumbnail_prompt` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ==========================================\n# 4. SCENARIO ORCHESTRATORS\n# ==========================================\n# This section contains functions that orchestrate the calls to the core\n# generation components (defined in Section 3) to implement the two main\n# use cases of the agent.","metadata":{}},{"cell_type":"markdown","source":"### 4.1. Scenario 1: Generate Metadata from Text Inputs\n# Use case: Generate initial metadata for a planned video/livestream\n# based on a topic idea and key talking points (theses).","metadata":{}},{"cell_type":"markdown","source":"#### 4.1.A. Orchestrator Function","metadata":{}},{"cell_type":"code","source":"def generate_metadata_from_text(topic: str, theses: str, use_trends_for_tags: bool = True) -> VideoMetadata:\n    \"\"\"\n    Generates complete video metadata (except chapters) from input topic and theses.\n\n    Args:\n        topic: User's topic idea.\n        theses: Key points or concepts for the video.\n        use_trends_for_tags: Whether to enhance tags using Google Trends.\n\n    Returns:\n        A VideoMetadata dictionary containing all generated metadata fields.\n    \"\"\"\n    print(\"\\n🎬 Starting Metadata Generation from Text Inputs...\")\n\n    metadata: VideoMetadata = DEFAULT_METADATA.copy()\n    metadata['chapters'] = \"\"  # Not generated in this scenario\n\n    try:\n        topic_gen, title_gen = generate_topic_title_from_inputs(topic, theses)\n        metadata['topic_name'] = topic_gen or topic\n        metadata['title'] = title_gen or \"Title Generation Failed\"\n    except Exception as e:\n        print(f\"⚠️ Topic/Title generation error: {e}\")\n        metadata['topic_name'] = topic\n        metadata['title'] = \"Title Generation Error\"\n\n    try:\n        description = generate_description_with_search(\n            topic_name=metadata['topic_name'],\n            title=metadata['title'],\n            main_points_or_transcript=theses\n        )\n        metadata['description'] = description or \"\"\n    except Exception as e:\n        print(f\"⚠️ Description generation error: {e}\")\n\n    try:\n        hashtags, tags = generate_tags_and_keywords(\n            topic_name=metadata['topic_name'],\n            description=metadata['description'],\n            use_trends=use_trends_for_tags\n        )\n        metadata['hashtags'] = hashtags\n        metadata['tags'] = tags\n    except Exception as e:\n        print(f\"⚠️ Tags/Keywords generation error: {e}\")\n\n    try:\n        thumbnail_prompt = generate_thumbnail_prompt(\n            topic_name=metadata['topic_name'],\n            title=metadata['title'],\n            main_points_or_transcript=theses\n        )\n        metadata['thumbnail_prompt'] = thumbnail_prompt or \"\"\n    except Exception as e:\n        print(f\"⚠️ Thumbnail prompt generation error: {e}\")\n\n    print(\"✅ Scenario 1 Metadata Generation Complete.\")\n    return metadata\n\nprint(\"✅ Orchestrator function `generate_metadata_from_text` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.2. Scenario 2: Generate Metadata from Full Transcript\n# Use case: Generate comprehensive metadata, including chapters,\n# for an existing video using its full text transcript.","metadata":{}},{"cell_type":"markdown","source":"#### 4.2.A. Helper: Load Transcript File","metadata":{}},{"cell_type":"code","source":"def load_transcript(file_path: str) -> str:\n    \"\"\"\n    Loads the video transcript from a given file path.\n\n    Args:\n        file_path: Path to the .txt file containing the transcript.\n\n    Returns:\n        The transcript as a string, or an empty string if loading fails.\n    \"\"\"\n    if not os.path.exists(file_path):\n        print(f\"❌ Transcript file not found: {file_path}\")\n        return \"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            text = f.read().strip()\n        if not text:\n            print(\"⚠️ Transcript file is empty.\")\n            return \"\"\n        print(f\"✅ Transcript loaded ({len(text)} characters).\")\n        return text\n    except Exception as e:\n        print(f\"❌ Error reading transcript: {e}\")\n        return \"\"\n\nprint(\"✅ Helper function `load_transcript` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 4.2.B. Orchestrator Function","metadata":{}},{"cell_type":"code","source":"def generate_metadata_from_transcript(transcript_text: str, use_trends_for_tags: bool = True) -> VideoMetadata:\n    \"\"\"\n    Generates full metadata for a YouTube video based on its transcript (Scenario 2).\n\n    Args:\n        transcript_text: Full video transcript as a string.\n        use_trends_for_tags: Whether to enhance tags using Google Trends.\n\n    Returns:\n        A dictionary of generated metadata conforming to VideoMetadata structure.\n    \"\"\"\n    if not transcript_text:\n        return DEFAULT_METADATA.copy()\n\n    metadata: VideoMetadata = DEFAULT_METADATA.copy()\n\n    try:\n        topic, title = generate_topic_title_from_transcript(transcript_text)\n        metadata['topic_name'] = topic or \"Topic Generation Failed\"\n        metadata['title'] = title or \"Title Generation Failed\"\n    except:\n        metadata['topic_name'] = \"Topic Generation Error\"\n        metadata['title'] = \"Title Generation Error\"\n\n    try:\n        description = generate_description_with_search(\n            topic_name=metadata['topic_name'],\n            title=metadata['title'],\n            main_points_or_transcript=transcript_text\n        )\n        metadata['description'] = description\n    except:\n        metadata['description'] = \"\"\n\n    try:\n        chapters = generate_chapters_from_transcript(transcript_text)\n        metadata['chapters'] = chapters or \"\"\n    except:\n        metadata['chapters'] = \"\"\n\n    try:\n        hashtags, tags = generate_tags_and_keywords(\n            topic_name=metadata['topic_name'],\n            description=metadata['description'],\n            use_trends=use_trends_for_tags\n        )\n        metadata['hashtags'] = hashtags\n        metadata['tags'] = tags\n    except:\n        metadata['hashtags'] = []\n        metadata['tags'] = []\n\n    try:\n        thumbnail = generate_thumbnail_prompt(\n            topic_name=metadata['topic_name'],\n            title=metadata['title'],\n            main_points_or_transcript=transcript_text\n        )\n        metadata['thumbnail_prompt'] = thumbnail\n    except:\n        metadata['thumbnail_prompt'] = \"\"\n\n    print(\"✅ Scenario 2 Metadata Generation Complete.\")\n    return metadata\n\nprint(\"✅ Orchestrator function `generate_metadata_from_transcript` defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ==========================================\n# 5. DEMONSTRATION\n# ==========================================\n# This section demonstrates how to use the orchestrator functions\n# defined in Section 4 for both Scenario 1 and Scenario 2.","metadata":{}},{"cell_type":"markdown","source":"### 5.1. Demo: Scenario 1 (Text Inputs)\n# Example of generating metadata based on an initial topic and theses.","metadata":{}},{"cell_type":"markdown","source":"#### 5.1.A. Define Example Inputs","metadata":{}},{"cell_type":"code","source":"# 📌 Define inputs for Scenario 1 (metadata from topic + theses)\ndemo_topic_s1 = \"AI Impact on Creative Jobs\"\ndemo_theses_s1 = \"\"\"\n- Explore the current state of AI tools (image generators, music AI, writing assistants) in creative fields.\n- Discuss potential job displacement vs. job augmentation (new roles, required skills).\n- Analyze the need for adaptation strategies for creative professionals.\n- Briefly touch upon ethical considerations and the future outlook for human creativity.\n\"\"\"\nprint(\"✅ Scenario 1 demo inputs defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 5.1.B. Run Generation","metadata":{}},{"cell_type":"code","source":"# 🔄 Run metadata generation for Scenario 1 (from topic + theses)\ns1_metadata_result = generate_metadata_from_text(\n    topic=demo_topic_s1,\n    theses=demo_theses_s1,\n    use_trends_for_tags=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 5.1.C. Render Output","metadata":{}},{"cell_type":"code","source":"# 🖼️ Display generated metadata for Scenario 1\nif s1_metadata_result:\n    render_metadata_md(s1_metadata_result)\nelse:\n    print(\"⚠️ Metadata not available.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5.2. Demo: Scenario 2 (Transcript)\n# Example of generating metadata based on a full video transcript file.","metadata":{}},{"cell_type":"markdown","source":"#### 5.2.A. Define Transcript Path & Load Data (from Kaggle Input)","metadata":{}},{"cell_type":"code","source":"# 📄 Load transcript file (Scenario 2)\ntranscript_file_path_s2 = \"/kaggle/input/test3-3/test3.txt\"  # Ensure this file is available via Kaggle input dataset\n\n# Load using previously defined helper function\nraw_transcript_s2 = load_transcript(transcript_file_path_s2) if callable(globals().get(\"load_transcript\", None)) else \"\"\n\n# Final check\nif not raw_transcript_s2:\n    print(\"⚠️ Transcript not loaded. Scenario 2 will be skipped.\")\nelse:\n    print(\"✅ Transcript loaded successfully. Proceeding to Scenario 2.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 5.2.B. Run Generation","metadata":{}},{"cell_type":"code","source":"# ▶️ Run Scenario 2 (if transcript is available)\ns2_metadata_result = None\nif raw_transcript_s2:\n    s2_metadata_result = generate_metadata_from_transcript(\n        transcript_text=raw_transcript_s2,\n        use_trends_for_tags=True\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 5.2.C. Render Output","metadata":{}},{"cell_type":"code","source":"# ▶️ Display metadata generated from transcript (Scenario 2)\nprint(\"\\n--- Scenario 2: Generated Metadata ---\") \nif s2_metadata_result: \n    render_metadata_md(s2_metadata_result) \nelif not raw_transcript_s2: \n    print(\"ℹ️ Skipped: No transcript loaded.\") \nelse: \n    print(\"⚠️ Metadata generation failed. See logs above.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ==========================================\n# 6. CONCLUSION & NEXT STEPS\n# ==========================================","metadata":{}},{"cell_type":"markdown","source":"## Conclusion\n\nThis notebook successfully demonstrates a GenAI-powered agent capable of automating YouTube metadata generation. By leveraging Gemini models, grounding via Google Search, and processing potentially long transcripts, the agent can produce relevant titles, topics, descriptions, tags, chapters, and thumbnail prompts for two common scenarios: planning upcoming streams and processing existing video transcripts.\n\nThis significantly reduces the manual effort involved in preparing video content for publication, allowing creators (like myself!) to focus more on the creative aspects.\n\n## Limitations and Future Work\n\nAs a first version developed within the scope of the Kaggle Capstone project, this agent certainly has room for improvement and refinement. Some current limitations include:\n\n* **Output Variability:** The quality and style of generated metadata depend heavily on the model's interpretation and can sometimes require manual tweaking.\n* **Input Dependency:** The quality of generated metadata (especially for Scenario 2) is dependent on the accuracy and completeness of the input transcript.\n* **Error Handling:** While basic error handling is implemented, more sophisticated checks and recovery mechanisms could be added.\n* **Static Configuration:** Model name, style, and other parameters are currently set globally.\n\nBased on the ideas for future development, potential next steps could include:\n\n* **Google Sheets Integration:** Connect the agent to Google Sheets for batch processing of video ideas or storing generated metadata.\n* **YouTube API Integration:** Directly upload or update video metadata to YouTube via its API.\n* **Speaker/Guest Database:** Integrate a database or lookup system for regular speakers/guests to automatically include their information and social links in descriptions.\n* **Output Evaluation:** Implement automated checks or use another LLM to evaluate the quality, relevance, and SEO potential of the generated metadata.\n* **Cost & Usage Tracking:** Add mechanisms to estimate and track API usage costs for generation.\n* **Enhanced Prompt Engineering:** Further refine prompts for even more consistent and controllable outputs.\n* **User Interface:** Develop a simple UI (e.g., using Gradio or Streamlit) for easier interaction.\n\nThis project serves as a solid foundation, and further development could turn it into an even more powerful tool for YouTube creators. Feedback, critical assessments, and suggestions for improvement are highly welcome!","metadata":{}}]}